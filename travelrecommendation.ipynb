{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\nfrom collections import defaultdict\nimport time\nimport ast\nfrom typing import List, Dict, Set, Tuple\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import TruncatedSVD\nfrom scipy.sparse import csr_matrix\n\nfrom IPython.display import display\nfrom IPython.display import Image\n\nclass PlaceRecommender:\n    def __init__(self):\n        self.users_df = None\n        self.places_df = None\n        self.interactions_df = None\n        self.place_features = None\n        self.user_profiles = None\n        # self.mlb = MultiLabelBinarizer()\n        self.train_interactions = pd.DataFrame()\n        self.test_interactions = pd.DataFrame()\n        self.svd_model = None\n        self.interaction_matrix = None\n        self.user_factors = None\n        self.place_factors = None\n        # self.popularity = None ???? We can add this too for recommending highly popular places\n    \n    \n    def preprocess_places_data(self, places_df):\n        tags = list(set([i.strip() for i in ','.join(places_df['tags']).split(',')]))\n        for tag in tags:\n            places_df[tag] = places_df['tags'].apply(lambda x: 1 if tag in x else 0)\n        category_features = pd.get_dummies(places_df['category'], prefix='category', dtype=int)\n        tags.extend(list(category_features.columns.values))\n        places_df = pd.concat([places_df, category_features], axis=1)\n        scaler = StandardScaler()\n        place_features = places_df[tags]\n        place_features = pd.DataFrame(\n            scaler.fit_transform(place_features),\n            index = place_features.index,\n            columns=place_features.columns\n        )\n        \n        return places_df, place_features\n\n\n    def preprocess_user_interaction_data(self, user_interactions_df):\n        interest_strength = {\"like\": 1,\n                             \"visit\" : 3,\n                             \"add_to_list\": 2\n                             }\n        \n        user_interactions_df['weighted_interaction'] = user_interactions_df['interaction_type'].apply(lambda x: interest_strength[x])\n        # Maybe interaction matrix?\n        return user_interactions_df\n    \n    def preprocess_users_data(self, user_df):\n        user_df['list_of_places'] = user_df['list_of_places'].apply(lambda x: ast.literal_eval(x))\n        return user_df\n\n\n    def load_and_preprocess_data(self, users_data, places_data, interactions_data, test_size=0.2):\n        \"\"\"Load and preprocess all necessary data.\"\"\"\n        # Load dataframes\n        self.users_df = self.preprocess_users_data(users_data)\n        self.places_df, self.place_features = self.preprocess_places_data(places_data)\n        self.interactions_df = self.preprocess_user_interaction_data(interactions_data)\n        grouped_user_interactions_df = self.interactions_df.groupby('user_id')\n        for _, group in grouped_user_interactions_df:\n            if len(group) > 2: #We would need to worry about zero start users.\n                train, test = train_test_split(group, test_size=test_size, random_state=42)\n                # display(train, test)\n                self.train_interactions = pd.concat([self.train_interactions, train])\n                self.test_interactions = pd.concat([self.test_interactions, test])\n                \n        user_indices = self.interactions_df['user_id'].astype('category').cat.codes #we might need this for data that is not sequential, right now is fine\n        place_indices = self.interactions_df['place_id'].astype('category').cat.codes\n        # display(place_indices, place_indices.unique().shape)\n\n        self.interaction_matrix = csr_matrix((self.interactions_df['weighted_interaction'], (user_indices, place_indices)), shape=(len(user_indices.unique()), len(place_indices)))\n        # display(self.interaction_matrix.shape)\n        self.svd_model = TruncatedSVD(n_components=50, random_state=42)\n        self.user_factors = self.svd_model.fit_transform(self.interaction_matrix)\n        self.place_factors = self.svd_model.components_.T\n        \n        ### We can also add how popular a place is?\n        \n\n    \n        \n    \n    def build_user_profiles(self):\n        \n        self.user_profiles = defaultdict(lambda: np.zeros(self.place_features.shape[1]))\n        \n        # Process explicit interactions (likes and add_to_list)\n        for _, row in self.interactions_df.iterrows():\n            user_id = row['user_id']\n            place_id = row['place_id']\n            interaction_type = row['interaction_type']\n            \n            # Weight different interaction types\n            weight = row['weighted_interaction']\n            \n            # Update user profile\n            if place_id in self.places_df.index:\n                place_feature_values = self.place_features.iloc[place_id-1].values.astype(np.float64)\n                self.user_profiles[user_id] += weight * place_feature_values\n        \n        # Normalize\n        for user_id in self.user_profiles:\n            profile = self.user_profiles[user_id]\n            if np.any(profile):\n                self.user_profiles[user_id] = profile / np.linalg.norm(profile)\n    \n    def get_recommendations(self, user_id, n_recommendations= 1):\n        \"\"\"Weight to cf and similarities is 0.4 and 0.6 respectively, these hyperparameters can be tuned to find a better answer\"\"\"\n        start_time = time.time()\n        \n        if user_id not in self.user_profiles:\n            return []\n        \n        # Calculate similarity between user profile and all places\n        cf_scores = np.zeros(len(self.places_df))\n        user_profile = self.user_profiles[user_id]\n        similarities = cosine_similarity([user_profile], self.place_features)[0]\n        place_indices = self.interactions_df['place_id'].astype('category').cat.codes.unique()\n        user_idx = self.interactions_df['user_id'].astype('category').cat.codes[self.interactions_df['user_id'] == user_id].iloc[0]\n        cf_predictions = np.dot(self.user_factors[user_idx], self.place_factors.T)\n        for idx, score in zip(place_indices, cf_predictions):\n            cf_scores[idx] = score\n        \n        # display(similarities.shape, cf_scores.shape)\n        combined_scores = 0.5 * similarities + 0.5 * cf_scores\n        \n        # Get places the user hasn't interacted with\n        user_interactions = set(self.train_interactions[self.train_interactions['user_id'] == user_id]['place_id'])\n        \n        # Create list of (place_id, similarity) tuples for places user hasn't interacted with\n        place_similarities = [\n            (place_id, sim) for place_id, sim in enumerate(combined_scores, 1)\n            if place_id not in user_interactions\n        ]\n        \n        # Sorting by similarity\n        recommendations = sorted(place_similarities, key=lambda x: x[1], reverse=True)[:n_recommendations]\n        # print(recommendations)\n        \n        detailed_recommendations = []\n        for place_id, similarity in recommendations:\n            place = self.places_df.iloc[place_id-1]\n            detailed_recommendations.append({\n                'place_id': place_id,\n                'place_name': place['place_name'],\n                'category': place['category'],\n                'tags': place['tags'],\n                'location': place['location'],\n                'similarity_score': similarity,\n                'response_time': time.time() - start_time\n            })\n        # display(detailed_recommendations)\n        return detailed_recommendations\n\n    def evaluate_precision_at_k(self, test_users, k):\n        precisions = []\n        \n        for user_id in self.test_interactions['user_id'].unique():\n            recommendations = self.get_recommendations(user_id, k)\n            if not recommendations:\n                continue\n                \n            # Get test set places for this user\n            test_places = set(self.test_interactions[self.test_interactions['user_id'] == user_id]['place_id'])\n            \n            # Calculate precision\n            recommended_places = {rec['place_id'] for rec in recommendations}\n            if recommended_places:\n                precision = len(test_places.intersection(recommended_places)) / len(recommended_places)\n                precisions.append(precision)\n        return np.mean(precisions) if precisions else 0.0\n\n    def evaluate_recall_at_k(self, test_users, k):\n        recalls = []\n        \n        for user_id in self.test_interactions['user_id'].unique():\n            recommendations = self.get_recommendations(user_id, k)\n            if not recommendations:\n                continue\n                \n            # Get test set places for this user\n            test_places = set(self.test_interactions[self.test_interactions['user_id'] == user_id]['place_id'])\n            \n            if test_places:\n                recommended_places = {rec['place_id'] for rec in recommendations}\n                recall = len(test_places.intersection(recommended_places)) / len(test_places)\n                recalls.append(recall)\n        \n        return np.mean(recalls) if recalls else 0.0\n\n    def evaluate_map(self, test_users, k):\n        ap_scores = []\n        \n        for user_id in self.test_interactions['user_id'].unique():\n            recommendations = self.get_recommendations(user_id, k)\n            if not recommendations:\n                continue\n                \n            test_places = set(self.test_interactions[self.test_interactions['user_id'] == user_id]['place_id'])\n            \n            if not test_places:\n                continue\n            relevant_count = 0\n            precisions = []\n            \n            for i, rec in enumerate(recommendations, 1):\n                if rec['place_id'] in test_places:\n                    relevant_count += 1\n                    precisions.append(relevant_count / i)\n            \n            if precisions:\n                ap_scores.append(sum(precisions) / len(test_places))\n        \n        return np.mean(ap_scores) if ap_scores else 0.0\n\n\n    def evaluate_response_time(self, test_users, k):\n        response_times = []\n        \n        for user_id in test_users:\n            start_time = time.time()\n            self.get_recommendations(user_id, n_recommendations=k)\n            response_time = time.time() - start_time\n            response_times.append(response_time)\n        \n        return {\n            'mean_response_time': np.mean(response_times),\n            'max_response_time': np.max(response_times),\n            'min_response_time': np.min(response_times),\n            'std_response_time': np.std(response_times)\n        }\n\n    def run_comprehensive_evaluation(self, test_users, k=1):\n        results = {\n            'precision_at_k': self.evaluate_precision_at_k(test_users, k),\n            'recall_at_k': self.evaluate_recall_at_k(test_users, k),\n            'mean_average_precision': self.evaluate_map(test_users, k),\n            'response_time_metrics': self.evaluate_response_time(test_users, k)\n        }\n        return results\n\ndef main():\n    # Initialize recommender\n    k = 4\n    recommender = PlaceRecommender()\n    \n    # Load and preprocess data\n    places_df = pd.read_csv(\"/kaggle/input/travel/places.csv\")\n    user_interactions_df = pd.read_csv(\"/kaggle/input/travel/user_interactions.csv\")\n    users_df = pd.read_csv(\"/kaggle/input/travel/users.csv\")\n    \n    recommender.load_and_preprocess_data(users_df, places_df, user_interactions_df)\n    recommender.build_user_profiles()\n    test_users = list(range(1,5)) \n    \n    evaluation_results = recommender.run_comprehensive_evaluation(test_users, k)\n    # display(evaluation_results)\n    # Print evaluation results\n    print(\"\\nEvaluation Results:\")\n    print(f\"Precision@{k}: {evaluation_results['precision_at_k']:.3f}\")\n    print(f\"Recall@{k} {evaluation_results['recall_at_k']:.3f}\")\n    print(f\"Mean Average Precision: {evaluation_results['mean_average_precision']:.3f}\")\n    print(\"\\nResponse Time Metrics:\")\n    for metric, value in evaluation_results['response_time_metrics'].items():\n        print(f\"{metric}: {value*1000:.2f}ms\")\n\nif __name__ == \"__main__\":\n    main()    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}